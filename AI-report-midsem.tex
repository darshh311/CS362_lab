\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\DeclareUnicodeCharacter{2212}{-}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Midsem Lab Report CS362\\
{{\footnotesize \textsuperscript{*}Note:\textbf{\href{https://github.com/darshh311/CS362_lab}{Code Repository Link}}}}
}

\author{\IEEEauthorblockN{Jinel Patel\textsuperscript{1} }
\IEEEauthorblockA{
\textsuperscript{1}201951075@iiitvadodara.ac.in}
\IEEEauthorblockN{ Kapadia Tathya\textsuperscript{2}}
\IEEEauthorblockA{
\textsuperscript{2}201951078@iiitvadodara.ac.in}
\and
\IEEEauthorblockN{Patel Darsh\textsuperscript{3}}
\IEEEauthorblockA{
\textsuperscript{3}201951111@iiitvadodara.ac.in}
\IEEEauthorblockN{Patel Het\textsuperscript{4}}
\IEEEauthorblockA{
\textsuperscript{4}201951112@iiitvadodara.ac.in}
}
\maketitle


\section*{Contents}
\section*{\textbf{Introduction}}
\section*{\textbf{Week 1 Lab Assignment 1}}
\section*{\textbf{Week 3 Lab Assignment 3}}
\section*{\textbf{Week 5 Lab Assignment 4}}
\section*{\textbf{Week 6 Lab Assignment 5}}
\section*{\textbf{\href{https://github.com/darshh311/CS362_lab}{Code Repository Link}}
}






\section{Introduction}
In these report we have included the observation,result and conclusion of the 4 experiments given to us in the lab.The 4 experiments we have included are:
\begin{enumerate}
    \item  Lab Assignment 1: Graph Search Agent for 8-Puzzle
    \item  Lab Assignment 3: TSP using Simulated Annealing
    \item  Lab Assignment 4: Game Playing Agent — Minimax
— Alpha-Beta Pruning
    \item Lab Assignment 5: Building Bayesian Networks in R
\end{enumerate}
We have understood and visualised our result in the form of tables and charts and thus discussed the same in these section.
\\
\\
We have executed the codes in Jupyter Notebook for Python and RStudio for R.In these section we have discussed the approach to the problem.We have attached the link to the codes in these section.
\\
\textbf{\href{https://github.com/darshh311/CS362_lab}{Code Repository Link}}


\section{Week I Lab assignment 1 }
\textbf{Learning Objective:}
To design a graph search agent and understand the use of a hash table, queue in state space search. In this lab, we need prior knowledge of the types of agents
involved and use this knowledge to solve a puzzle called 8-puzzle.
\begin{figure}[htbp]
\centerline{\includegraphics[width=5cm, height=4cm]{8 puzzle.png}}
\caption{Initial and Final state of 8-Puzzle \cite{b2}}
\label{fig}
\end{figure}
8-Puzzle consist of a 3x3 matrix with the tiles numbered as shown and there is one white space available in which the tile can move.
\subsection{Part A}
Write a pseudocode for a graph search agent. Represent
the agent in the form of a flow chart. Clearly mention all the
implementation details with reasons.
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{flowchart.png}}
\caption{Flowchart for Agent}
\label{fig}
\end{figure}
\newline
\textbf{Algorithm:}
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.7]{algorithm.png}}
\end{figure}


\subsection{Part B}
Write a collection of functions imitating the environment
for Puzzle-8. Our code consists of following functions:
\begin{itemize}
    \item \textbf{Heuritic 1:} 
Heuristic for calculating the distance of goal state
using Manhattan distance.\cite{b6}
\\
\\
Parameters:
\\
current state(np.ndarray): A 3x3 array with each
cell containing unique elements as in current state
\\
goal state(np.ndarray): A 3x3 array with each
cell containing unique elements as in goal state
\\
\\
returns:
\\
heuristic1(int): Heuristic value
\\
    \item \textbf{Heuristic 2:}
Heuristic for calculating the distance of goal state
using number of misplaced tiles
\\
\\
Parameters:
\\
current state(np.ndarray): A 3x3 array with each
cell containing unique elements as in current state
\\
goal state(np.ndarray): A 3x3 array with each
cell containing unique elements as in goal state
\\
\\
returns:
\\
heuristic2(int): Heuristic value
\\
   \item \textbf{generate instance:}
\\  
\\
Parameters:
\\
goal state(np.ndarray): A 3x3 array with each cell containing unique elements representing the goal
\\
depthstate(int): The depth at which the state is to be
generated
\\
debug(bool): Get intermediate states and the heuristic
values.Default value is False
\\
\\
returns:
\\
curr state(np.ndarray): A 3x3 array with each cell containing unique elements representing the state at the given depth form, the goal state   
\\
     \item \textbf{get possible next state:}
function to get the next possible state from the current state from the environment
\\
Parameters:
\\
current state(np.ndarray): A 3x3 array representing the current states
parent(string): The path taken to reach the current state
from initial Arrangement
\\
\\
returns:
\\
possible moves(list): List of possible states from current state
\\
possible paths(list): List of possible paths moves from current state
\\
       \item \textbf{sort:}
This function sorts the state according to the heuristic values generated from one of the heuristic function as selected.
\\
Parameters:
\\
possible moves(list): List of possible states from current state
goal state(np.ndarray): A 3x3  array representing the goal state
heuristic(Integer): An integer indicating the heuristic
function to use from 1 or 2.
possible paths(list): List of possible moves from current state
\\
\\
returns:
\\
sorted possible moves(list): List of possible states from current state, sorted according to heuristic
\\
      \item \textbf{solution:}
This function returns success if the goal state is found and prints failure if no goal state is found or the programme is strucked
\\
Parameters:
current state(np.ndarray): A 3x3 array representing the current state
goal state(np.ndarray): A 3x3 array representing the goal state
heuristic(Integer): An integer indicating the heuristic
function to use.
\\
\\
\end{itemize}

\subsection{Part C}
Describe what is Iterative Deepening Search.
\\
\\
\textbf{Iterative deepening depth first search (IDDFS)} Iterative Deepening search was mainly introduced to overcome the problems faced by BFS and DFS algorithms.We do a DFS search in BFS algorithm.The graph/tree is searched in DFS pattern but is allowed to go to a certain depth only.So we do a DFS in BFS algorithm.It is an approach which takes lower space and  optimal time compared to DFS or BFS.This would be clearly explained from the following figure\cite{b1}
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.7]{iddfs.png}}
\caption{Iterative deepening search example\cite{b7}}
\label{fig}
\end{figure}
Suppose b is the branching factor and depth is d then we have time complexity ans Space Complexity as
\\
\textbf{Time Complexity:} O(b\textsuperscript{d})
\\
\textbf{Space Complexity:} O(bd)
\\
\subsection{Part D}
Considering the cost associated with every move to be the
same (uniform cost), write a function which can backtrack
and produce the path taken to reach the goal state from the
source/initial state
\\
\\
The Code Snippet for the function is given Under as follows:
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.4]{function.png}}
\caption{Function to backtrack}
\label{fig}
\end{figure}

\subsection{Part E}
\newline
Generate Puzzle-8 instances with the goal state at depth “d”.
\\
\\
The Function generating these instances is "GeneralInstances" and the snippet of output is as follows:
\begin{figure}[htbp]
\centerline{\includegraphics[scale=1]{instance.png}}
\caption{Function to backtrack}
\label{fig}
\end{figure}

\subsection{Part F}
\newline
Prepare a table indicating the memory and time requirements to solve Puzzle-8 instances (depth “d”) using your graph search agent.
\\
For tracking the time and memory there are packages available in python and we have used memory\_profile.The three tables generated are given below and they are made considering the 2 different hueristic function and without any hueristic function.

\begin{figure}
\centerline{\includegraphics[scale=0.5]{table1.png}}
{        Using Manhattan Distance Heuristic}

\end{figure}
\\

\begin{figure}
\centerline{\includegraphics[scale=0.5]{table2.png}}
{        Using Misplaced tiles Heuristic}

\end{figure}
\\

\begin{figure}
\centerline{\includegraphics[scale=0.5]{table3.png}}
{        Without using any Heuristic}

\end{figure}


\section{Week 3 Lab Assignment 3}
\textbf{Learning Objective:} 
Non-deterministic Search | Simulated
Annealing For problems with large search spaces, randomized search becomes a meaningful option given partial/full-information about the domain.
\\
\\
\textbf{Problem Statement:}
Travelling Salesman Problem (TSP) is a hard problem, and is simple to state. Given a graph in which the nodes are locations of cities, and edges are labelled with the cost of travelling between cities, find a cycle containing each city exactly once, such that the total cost of the tour is as low as possible.
\\
\\
The entire code for week 3 has been coded in Jupyter notebook and you can find the link for that code here.
\href{https://github.com/darshh311/CS362_lab}{Code Repository Link}
\\
\\
Here we are visiting 25 random nodes/points.
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_1.png}}
\caption{Scatter plot for 25 nodes}
\label{fig}
\end{figure}
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.75]{w3_img_2.png}}
\caption{Comparison between the routes of 25 nodes}
\label{fig}
\end{figure}
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_3.png}}
\caption{Fitness curve for 25 nodes}
\label{fig}
\end{figure}
\\
\\

The second plot graph in fig 7 is showing the optimal path to returning to the starting point covering all the nodes using simulated annealing to reduce the cost.
\\
\\
Fig 8 shows how simulated annealing reduces the cost over each iteration. The fitness curve shows the behavior of the cost w.r.t to the number of iterations we are running to obtain the optimal path. Initially the cost is higher than the random path cost but it significantly reduces over successive iterations and as soon as the temperature is low it becomes harder to accept the worst solution cost, there the cost moves towards optimal cost with the decrease in temperature, after some iterations the curve becomes stable - so we can conclude that not many changes are happening and the cost that we are getting is the optimal cost.





\subsection{Part A}
 For the state of Rajasthan, find out at least twenty important tourist locations.  Suppose your relatives are about to visit you next week.  Use Simulated Annealing to plan a cost effective tour of Rajasthan.  It is reasonable to assume that the cost of traveling between two locations is proportional to the distance between them.
\\
\\
We have selected 25 locations for us to visit. Now we will calculate the euclidean distance for all the pair of coordinates for all the locations. After that we will plot a random route connecting all the nodes and using simulated annealing we will find the optimal cost to cover all the locations/nodes shown in fig 10.\cite{b4}
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_4.png}}
\caption{Scatter plot for 25 locations in Rajasthan}
\label{fig}
\end{figure}
\\
\\

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_5.png}}
\caption{Optimal path for 25 locations in Rajasthan}
\label{fig}
\end{figure}
\\
\\


\subsection{Part B}
VLSI: \href{http://www.math.uwaterloo.ca/tsp/vlsi/index.html}{Dataset}
Attempt at least five problems from the above list and compare
your result
\\
\\

Here we will be doing the same procedure to find the optimal route as we did in the Rajasthan problem in the datasets from VLSI viz. 131 points, 237 points, 343 points, 379 points, and 380 points.
\\
\\
\subsubsection{XQF131 - 131 points}
\\
\\
--
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_6.png}}

\label{fig}
\end{figure}
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_7.png}}
\caption{Plots for 131 points}
\label{fig}
\end{figure}
\\
\\
\subsubsection{XQF237 - 237 points}
\\
\\
-
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.25]{237-2.png}}
\label{fig}
\end{figure}
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.75]{237-3.png}}
\caption{Plot for 237 points}
\label{fig}
\end{figure}

\subsubsection{PMA343 - 343 points}

--
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_9.png}}
\caption{Plot for 343 points}
\label{fig}
\end{figure}
\\
\\
\subsubsection{PKA379 - 379 points}
--
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_10.png}}
\caption{Plot for 379 points}
\label{fig}
\end{figure}
\\
\\
\subsubsection{BLC380 - 380 points}
--
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_11.png}}
\caption{Plot for 380 points}
\label{fig}
\end{figure}
\subsection{Comparing Results}
In fig 16 we can see that the final cost that we are getting i.e the optimal cost is smaller than the cost that we get when we use a random route. When we compare our results with the ones given in the VLSI datasets we find that our calculated final cost is comparable with the optimal cost of VLSI.
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_12.png}}
\caption{Plot for 380 points}
\label{fig}
\end{figure}
We can also further decrease the cost by increasing the iterations and using heuristic functions to solve the traveling salesman problem.
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w3_img_13.png}}

\label{fig}
\end{figure}






\section{WEEK 5 LAB ASSIGNMENT 4}
\textbf{Learning Objective:} Game Playing Agent | Minimax |
Alpha-Beta Pruning

\subsection{Part 1}
What is the size of the game tree for Noughts and Crosses? Sketch the game tree.
\\
\\
Considering the Depths at every level we have
\\
At Depth 1 = 9 Possibilities
\\
At Depth 2 = 9*8 Possibilities
\\ 
At Depth 3 = 9*8*7 Possibilities
\\
So we have total number of states available are almost equal to 10\textsuperscript{6} 
\\
The Graph tree can be given as Follows:
\newline
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.65]{graphtree.png}}
\caption{Graph of the tree}
\label{fig}
\end{figure}
\\
\\
\subsection{Part 2}
Read about the game of Nim (a player left with no move losing the game). For the initial configuration of the game with three piles of objects as shown in Figure, show that regardless of the strategy of player-1, player-2 will always win. Try to explain the reason with the MINIMAX value backup argument on the game tree
\\
The initial Configuration of the nim game given to us is:
\begin{figure}[htbp]
\centerline{\includegraphics[scale=1]{nim.png}}
\caption{Graph of the tree}
\label{fig}
\end{figure}
\\
To show that Player 2 always win we use the minimax algorithm and the player is allowed to take from one column only so if the player moves such that the XOR of all the three towers become zero\cite{b9} so if the player 1 proceeds like this player 2 would always win as shown in the figure:
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=1]{p1p2.png}}
\caption{Player taking turns in Nim}
\label{fig}
\end{figure}

\subsection{Part 3}
Implement MINIMAX and alpha-beta pruning agents. Report on number of evaluated nodes for Noughts and Crosses
game tree.\cite{b5}

The given code are here\href{https://github.com/darshh311/CS362_lab}{Code Repository Link}
\\
\\
The output snippet is given as shown in figure 20:
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.9]{minimax2.png}}
\caption{Output of Minimax and Alpha beta-pruning}
\label{fig}
\end{figure}

\subsection{Part 4}
Using recurrence relation show that under perfect ordering of leaf nodes, the alpha-beta pruning time complexity is O(bm/2), where b is the effective branching factor and m is the depth of the tree.
\\
Let m be the depth of the tree and b be the effective
branching factor.
\\
T(m) be the minimum number of states to be traversed to
find the exact value of the current state, and
\\
K(m) be the minimum number of states to be traversed to
find the bound on the current state.
\\
\\
We get the equation as:
\begin{equation}
T(m)=T(m-1)+(b-1)K(m-1)\label{eq}
\end{equation}
\\
T(m-1) is to traverse to child node and find the
exact value, and (b-1)K(m-1) is to find min/max bound for
the current depth of the tree as we have to find using recursion.
\\
\\
In best case, we know that
\\
\begin{equation}
T(0) = K(0) = 1\label{eq}
\end{equation}
\\
exact value of one child is
\begin{equation}
K(m)=T(m−1)\label{eq}
\end{equation}
\\
From the given relation we have:
\\
\begin{equation}
T(m) = T(m−1) + (b−1)K(m−1)\label{eq}
\end{equation}
\\
\begin{equation}
T(m−1) = T(m-2) + (b−1)K(m−2)\label{eq}
\end{equation}
\\
so on we get 
\\
\begin{equation}
T(1) = T(0) + (b-1)K(0) = 1 + b-1 = b(10)\label{eq}
\end{equation}
\\
using equation 4 and 5 we get
\\
\begin{equation}
T(m) = T(m−2)+(b−1)K(m−2)+(b−1)K(m−1) \label{eq}
\end{equation}
\\
\begin{equation}
\begin{split}
T(m) = T(m − 3) + (b − 1)K(m − 3)
\\+ (b − 1)K(m − 2)+ (b-1)K(m-1) \label{eq}
\end{split}
\end{equation}
\\
Using 3 and 8 we get
\\
\begin{equation}
\begin{split}
T(m) = T(m − 2) + (b − 1)T(m − 3) +
\\(b − 1)T(m − 2)= b(T(m-2)) + (b-1)T(m-3) \label{eq}
\end{split}
\end{equation}
\\
\\
Now we can clearly say that
\begin{equation}
T(m − 2) > T(m − 3) \label{eq}
\end{equation}
\\
So we can predict
\\
\begin{equation}
T(m) < (2b − 1)T(m − 2) \label{eq}
\end{equation}
\\
\\
Considering large values of b
\begin{equation}
T(m) < 2bT(m − 2) \label{eq}
\end{equation}
\\
From these we can conclude from these that the effective branching factor is less than \sqrt{2b}
\\
\\
Time Complexity  = O(b\textsuperscript{m/2})

\section{WEEK 6 LAB ASSIGNMENT 5}
\textbf{Learning Objective:}
Understand the graphical models for inference under uncertainty, build Bayesian Network in R, Learn the structure and CPTs from Data, naive Bayes classification with dependency between features.
\\
\\
\textbf{Problem Statement:}
A table containing grades earned by students in respective courses is made available to you in (codes folder) 2020\_bn\_nb\_data.txt.

\\
\subsection{Part A}
Here let us consider the grades earned in each of the courses as random variable and learn the dependencies between the courses.
\\
The dependencies can be learned using  'bnlearn package in R as well as using the function called hill climbing greedy search. 
\\
\\
Hill climbing is the score-based algorithm. As our dataset is categorical we learn the scores of discrete Bayesian Network - k2 and bic - and compare both of them.\cite{b3}
\\
\\

\subsubsection{Using k2 score}
\\
\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w5_img_1.png}}
\caption{Hill Climbing Bayesian Network using K2 score}
\label{fig}
\end{figure}

There are in total 7 arcs in fig 21 and the model string is showing this dependency: '[IT161] [IT101|IT161] [MA101|IT101] [HS101|IT101]
[EC100|MA101] [PH160|HS10] [EC160|EC100]
[PH100|EC100]’

\subsubsection{Using bic score}

There are only two arcs in fig 22 and the model string showing this dependency is '[EC100] [EC160] [IT101] [IT161] [PH160] [HS101]
[MA101|EC100] [PH100|EC100]'

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w5_img_2.png}}
\caption{Hill Climbing Bayesian Network using bic score}
\label{fig}
\end{figure}
\\
\\
Since we are interested to find the dependency of the
different grades, we can see that the k2 score gives a better idea
of how the scores are dependent on each other, furthermore k2 is generally considered a good choice for large datasets. So, for the further parts, we’ll only use the network learned
using the k2 score.\cite{b8}
\\
\\

\subsection{Part 2}
Using the data, learn the CPTs for each course node.
\\
\\
According to the network learned using the k2 score, we
plot the conditional probabilities.
\\
\\

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w5_img_3.png}}
\caption{Conditional probability distributions made form the
CPTs of the learned data}
\label{fig}
\end{figure}

\subsection{Part 3}
What grade will a student get in PH100 if he earns DD in
EC100, CC in IT101 and CD in MA101.
\\
\\
We use the "cpdist" function of the "bnlearn" package in R to get distribution of grades of PH100 when the student has earned DD in EC100, CC in IT101 and CD in MA101.That distribution graph is shown in fig 23 and the distribution table shown below.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w5_img_4.png}}
\caption{Probability distribution of getting a grade in PH100
as per the given evidence}
\label{fig}
\end{figure}

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w5_img_5.png}}

\label{fig}
\end{figure}


\subsection{Part 4}
The last column suggests if the student is eligible for internship or not.
Now we take 70 percent for training and build a naive Bayes classifier, which will take in students performance and return if the student is eligible for internship or not. Now test the model for the remaining 30 percent. Repeat the experiment for 20 iterations.
\\
\\
So now we split the dataset of 231 into training of 162 and testing of 69 samples.
\\
\\
We use the NBC using the function 'nb' from the package 'bnclassify' in R tolearn the naive Bayes network structure and then the function ’lp’ to learn the parameters. Here, we do not assume any dependency between
the grade nodes, therefore classifier learns assuming the data to be independent.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w5_img_6.png}}
\caption{Naive Bayes Classifier for independent data}
\label{fig}
\end{figure}

\\
\\
This network model learns on the training dataset that we split. The accuracy has been shown in the table below.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w5_img_7.png}}

\label{fig}
\end{figure}
\\
\\
\subsection{Part 5}
Repeat part 4, just considering the grades earned are dependent.
\\
\\
To learn the features we use 'tan-chow' function. The classifier learns on the structure as shown below.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.25]{w5_img_8.png}}
\caption{Naive Bayes Classifier for dependent data}
\label{fig}
\end{figure}
\\
\\
This network learns on training dataset that we split in the earlier part.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{w5_img_9.png}}

\label{fig}
\end{figure}
\section*{Conclusion}
\\
\\
As we have demonstrated in the above problems we have successfully solved 8 puzzle problem,Travelling salesman problem (tsp), Noughts and Crosses Game, Nim game and understood the Bayesian graphical Models to build network Graphs.
\\
\\
The importance of Heuristic plays an important role in solving the real life problems as as solving the problems in considerable amount of time as compared without Heuristic functions saving time as well as memory for big dataset problems.
\\
\\
In the Travelling Salesman problem we learned to use simulated annealing to find the optimal path or the sub optimal path.
\\
\\
From our observation in the minimax algo we find that alpha-beta pruning is not a different algorithm than mini-max it is just a speed up process which does not evaluate approximate values instead evaluates to perfectly same values.
\\
\\
Lastly we explored the Bayesian network and were able to model it using grades data-set, we then calculated Conditional Probability Tables (CPTs) for them and saw how they were dependent.


\section*{Acknowledgment}
\\
We would like to thank out Prof. Pratik Shah and our TA Sir Prashant Dhameja as well as my colleagues.it is due to the lectures in AI that we were able to understand the problem as well as able to solve it.
\\
We would also like to thank the sources as well the online materials that we have used.

\begin{thebibliography}{00}
\bibitem{b1} Russell, S. and Norvig, P., 2002. Artificial intelligence: a modern approach.
\bibitem{b2}8 puzzle problem -benchpartner.com
\bibitem{b3}Shah Pratik, An Elementary Introduction to Graphical Models February
2021
\bibitem{b4}Zhou, Ai-Hua, Traveling-salesman-problem algorithm based on simulated annealing and gene-expression programming. Information 10.1 2019.
\bibitem{b5} Best-Case Analysis of Alpha-Beta Pruning. http://www.cs.utsa.edu/ ∼bylander/cs5233/a-b-analysis.pdf.
\bibitem{b6} Khemani, D., 2020. Artificial Intelligence: The Big Picture. Resonance: Journal of Science Education, 25(1).
\bibitem{b7}iddfs - stackoverflow.
\bibitem{b8}Bojan Mihaljevic,´ Bayesian networks with R November 2018.
\bibitem{b9}Marianne Freiberger, Play to win with Nim.July 21, 2014.
\end{thebibliography}
\vspace{12pt}


\end{document}
